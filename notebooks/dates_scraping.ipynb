{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from helper.data_wrangling import load_and_clean_movies_df\n",
    "from helper.scrap_helper import *\n",
    "\n",
    "# Make sure that if any dependencies changes it will be reflected in the notebook (From the ML course)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = load_and_clean_movies_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge the entire dataframe of the movies with the one containing those selected with their IMDB ids in order to work only with this subset of movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.read_csv('data/merged_data.csv', sep=',')\n",
    "merged_data = merged_data.rename(columns={\"0\": \"wikipedia_ID\", \"2\": \"title\"})\n",
    "\n",
    "merged_data = pd.merge(df_movies, merged_data, on='wikipedia_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18181 movies among 28415 for which we have the year and month of release.\n"
     ]
    }
   ],
   "source": [
    "n_total = merged_data.shape[0]\n",
    "no_dates = merged_data.loc[(merged_data.release_month != '<NA>') & (merged_data.release_year != '<NA>')].shape[0]\n",
    "\n",
    "print(f\"There are {no_dates} movies among {n_total} for which we have the year and month of release.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the wikipedia ID we have for each movie to scrap information from wikidata about the release dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe of movies\n",
    "merged_scraped = merged_data.copy()\n",
    "\n",
    "merged_data = merged_data.rename(columns={\"release_year\": \"release_year_x\", \"release_month\": \"release_month_x\"})\n",
    "\n",
    "dates_merged = merged_data[['wikipedia_ID', 'release_year_x', 'release_month_x']].copy()\n",
    "\n",
    "# add empty columns that are going to be fill by scraping the dates\n",
    "dates_merged['release_year_y'] = ''\n",
    "dates_merged['release_month_y'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file where we will be scraping to\n",
    "dates_merged.tocsv('dates_scraped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable corresponding to how many movies we scraped, in case we need to\n",
    "# to re launch the scraping while some data is already scraped.\n",
    "number_scraped = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all we need to scrap ! Let's do it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO RUN ONLY IF DATES_SCRAPED ALREADY EXITS\n",
    "# If we need to continue to scrap on a file we've already started to scrap to.\n",
    "dates_merged = pd.read_csv('dates_scraped.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dates_merged.iloc[number_scraped:].iterrows():\n",
    "    w_id = row.wikipedia_ID\n",
    "    year, month = format_date_numeric(get_release_date(wikidata_from_wikipedia_id(w_id)[1]))\n",
    "    dates_merged.loc[idx, 'release_year_y'] = year\n",
    "    dates_merged.loc[idx, 'release_month_y'] = month\n",
    "\n",
    "    # save the file with the new scraped dates\n",
    "    dates_merged.to_csv('dates_scraped.csv', index=False)\n",
    "    number_scraped += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
